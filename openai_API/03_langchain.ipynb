{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMChain\n",
    "\n",
    "LLMChain es una de las cadenas más utilizadas. Lo que hace es unir dos elementos para que se pueda interactuar con las LLMs de manera más sencilla\n",
    "\n",
    "Une modelo LLM (puede ser llama, chatGPT, etc.) y los templates de prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "import openai\n",
    "import config\n",
    "\n",
    "api = config.OPENAI_API_KEY\n",
    "#  KEY ='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'\n",
    "openai.api_key = api \n",
    "\n",
    "prompt = \"\"\"\n",
    "Eres un asistente virtual experto en {tema}, que responde con una \n",
    "lista de 3 conceptos clave sobre el mismo. Solo enumeras los \n",
    "3 conceptos\n",
    "\"\"\"\n",
    "\n",
    "template = PromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model= \"gpt-4\", openai_api_key= api)            # nuestro modelo llm\n",
    "\n",
    "cadena_LLM = LLMChain(\n",
    "    llm= llm,             # para esta cadena utiiliza el modleo llm\n",
    "    prompt= template      #para el prompt utiliza esta plantilla \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cadena es el elemento con el que se va a interactuar ahora en las predicciones. \n",
    "\n",
    "Lo que hace ahora esta cadena es tomar tu input (El tema), le da el formato al prompt que usará y envia el prompt construido al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Aprendizaje automático\\n2. Redes neuronales\\n3. Procesamiento de lenguaje natural'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadena_LLM.predict(tema= 'Inteligencia artificial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequentialChain\n",
    "\n",
    "Para muchos casos de uso solo enviar texto no es suficiente, se requiere qeu una secuencia de procesos se ejecute en ese orden. SimpleSequentialChain o SequentialChain permiten encadenar varios procesos de manera secuencial.\n",
    "\n",
    "Cuando queremos que la salida de un modelo funcione como entrada para otro.\n",
    "\n",
    "SequentialChain brinda más flexibilidad que simpleSequentialChain, pues puede recibir multiples entradasy generar multiples salidas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model= \"gpt-4\", openai_api_key= api)                # nuestro modelo llm\n",
    "\n",
    "prompt = \"\"\"\n",
    "Eres un asistente virtual experto en {tema}, que responde con una \n",
    "lista de 3 conceptos clave sobre el mismo. Solo enumeras los \n",
    "3 conceptos\n",
    "\"\"\"\n",
    "\n",
    "template = PromptTemplate.from_template(prompt)\n",
    "cadena_lista = LLMChain(llm= llm, prompt= template,\n",
    "                        output_key=  \"lista_conceptos\")           # con esto le decimos a langhain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una caden la cual va a recibir la salida de la cadena cadena_LLM y lo precesa para generar otro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"\"\"\n",
    "Eres un asistente virtual que recibe una lista \n",
    "de conceptos de un area del conocimiento y debe\n",
    "devolver cual de esos conceptos es mejor aprender\n",
    "primero. Los conceptos son: {lista_conceptos}\n",
    "\"\"\"\n",
    "\n",
    "template = PromptTemplate.from_template(prompt)\n",
    "cadena_inicio = LLMChain(llm= llm, prompt= template, output_key=\"donde_iniciar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "cadenas = SequentialChain(chains= [cadena_lista, cadena_inicio], \n",
    "                          input_variables=[\"tema\"], \n",
    "                          output_variables=[\"lista_conceptos\", \"donde_iniciar\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tema': 'Montañismo',\n",
       " 'lista_conceptos': '1. Equipo de Montañismo: Incluye todo el equipo necesario para realizar una ascensión segura y exitosa, como ropa adecuada, botas de montaña, crampones, piolet, casco, arnés, cuerdas, carabinas y equipo de campamento.\\n\\n2. Técnicas de Ascenso y Descenso: Se refieren a las habilidades necesarias para escalar y descender de manera segura una montaña, incluyendo la escalada en roca, el uso de crampones y piolet, la navegación por terrenos difíciles y la gestión de riesgos de avalanchas.\\n\\n3. Aclimatación: Es el proceso de adaptación del cuerpo a la disminución del oxígeno disponible a grandes altitudes. Es vital para prevenir enfermedades de altura potencialmente mortales.',\n",
       " 'donde_iniciar': 'Es mejor aprender primero \"Equipo de Montañismo\". Este conocimiento proporcionará una base sólida sobre las herramientas y equipo necesario para la actividad. Una vez que se entiendan y manejen los equipos, será más fácil entender y aplicar las \"Técnicas de Ascenso y Descenso\". \"Aclimatación\" también es un concepto vital, pero su aplicación depende en gran medida de tener una comprensión sólida del equipo y las técnicas básicas de montañismo.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadenas({\"tema\": \"Montañismo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. Aprendizaje automático\n",
      "2. Procesamiento del lenguaje natural\n",
      "3. Redes neuronales artificiales\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mEs recomendable comenzar con el concepto de \"Aprendizaje automático\". Este es un área más amplia que incluye tanto el procesamiento del lenguaje natural como las redes neuronales artificiales. Al entender los fundamentos del aprendizaje automático, te será más fácil comprender los otros dos conceptos.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Es recomendable comenzar con el concepto de \"Aprendizaje automático\". Este es un área más amplia que incluye tanto el procesamiento del lenguaje natural como las redes neuronales artificiales. Al entender los fundamentos del aprendizaje automático, te será más fácil comprender los otros dos conceptos.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo con simple sequential chain\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "simple = SimpleSequentialChain(chains= [cadena_lista, cadena_inicio], \n",
    "                               verbose=True)\n",
    "simple.run(\"Inteligencia artificial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otros ejemplos\n",
    "\n",
    "## operaciones matemáticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mathChain\n",
    "\n",
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\plane\\OneDrive\\Escritorio\\COMPUTING SCIENCE\\Apuntes_plantillas\\venv\\lib\\site-packages\\langchain\\chains\\llm_math\\base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "Cuanto es 432*12?\u001b[32;1m\u001b[1;3m```text\n",
      "432 * 12\n",
      "```\n",
      "...numexpr.evaluate(\"432 * 12\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m5184\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 5184'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadena_mate= LLMMathChain(llm= llm, verbose= True)\n",
    "cadena_mate.run(\"Cuanto es 432*12?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformchain\n",
    "\n",
    "Permite modificar y transformar un prompt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
