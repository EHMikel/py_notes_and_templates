{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELOS\n",
    "\n",
    "Estos son los modelos los cuales son los que se encargarán de procesar nuestro texto. En el caso de usar OpenAI se tiene que crear la variable ambiente llamada \"OPENAI_API_KEY\" con la api key de openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp, OpenAI\n",
    "import openai\n",
    "import config\n",
    "\n",
    "api = config.OPENAI_API_KEY\n",
    "#  KEY ='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'\n",
    "openai.api_key = api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_00 = \"gpt-4-1106-preview\"        # este no funciona con langchain\n",
    "model_01 = \"gpt-3.5-turbo-0613\"        # no funciona\n",
    "mdoel_02 = \"text-davinci-003\"          # si funciona\n",
    "\n",
    "llm_openai = OpenAI(\n",
    "    model_name= \"text-davinci-003\",\n",
    "    openai_api_key= api, \n",
    "    )  # aqui se pueden establecer los parametros de la respuesta de chat gpt como temperatura, max_tokens, etc\n",
    "\n",
    "#llm_llama = LlamaCpp(model_path=\"./llamacpp/models/7B/ggml-model-q4_0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta_openai = llm_openai(\"Dame una lista de los 5 mejores modelos LLM actuales, para nlp\")\n",
    "# respuesta_llama = llm_llama(\"Dame una listat de 5 mejores llm actuales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. BERT (Bidirectional Encoder Representations from Transformers)\n",
      "2. GPT-2 (Generative Pre-trained Transformer 2)\n",
      "3. XLNet\n",
      "4. RoBERTa (Robustly Optimized BERT Pretraining)\n",
      "5. ALBERT (A Lite BERT)\n"
     ]
    }
   ],
   "source": [
    "print(respuesta_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELOS DE CHAT\n",
    "\n",
    "Los modelos que se utilizan para compeltar texto, sin embargo, se pueden usar modelos específicos como chat gpt para chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatGPT = ChatOpenAI(openai_api_key= api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Aquí tienes una lista de algunos de los mejores modelos de LLM (Modelos de Lenguaje de Aprendizaje Profundo) para NLP (Procesamiento del Lenguaje Natural) en la actualidad:\\n\\n1. GPT-3 (Generative Pre-trained Transformer 3): Desarrollado por OpenAI, es uno de los modelos más avanzados y potentes en NLP. Cuenta con 175 mil millones de parámetros y ha demostrado ser capaz de realizar tareas de generación de texto, traducción, resumen, entre otros.\\n\\n2. BERT (Bidirectional Encoder Representations from Transformers): Desarrollado por Google, se basa en la arquitectura de Transformer. Es conocido por su capacidad de comprensión contextual y ha sido utilizado en una amplia gama de tareas de NLP, como etiquetado de entidades, clasificación de texto y respuesta a preguntas.\\n\\n3. GPT-2 (Generative Pre-trained Transformer 2): También desarrollado por OpenAI, es un modelo anterior a GPT-3. Aunque cuenta con menos parámetros, sigue siendo muy efectivo en tareas de generación de texto, traducción y resumen.\\n\\n4. RoBERTa (Robustly Optimized BERT): Es una versión mejorada de BERT desarrollada por Facebook AI. RoBERTa ha obtenido resultados sobresalientes en varias tareas de NLP, especialmente en tareas de comprensión de texto y clasificación de sentiment.\\n\\n5. XLNet: Es otro modelo basado en la arquitectura de Transformer, pero con algunas mejoras. XLNet ha demostrado ser muy efectivo en tareas de modelado de lenguaje, generación de texto y traducción.\\n\\nEs importante tener en cuenta que la clasificación de los mejores modelos puede variar dependiendo del contexto y los objetivos específicos de cada tarea en NLP.'\n"
     ]
    }
   ],
   "source": [
    "respuesta_gpt = chatGPT([HumanMessage(content=\"Dame una lista de los 5 mejores modelos LLM actuales, para nlp\")])\n",
    "print(respuesta_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquí tienes una lista de algunos de los mejores modelos de LLM (Modelos de Lenguaje de Aprendizaje Profundo) para NLP (Procesamiento del Lenguaje Natural) en la actualidad:\n",
      "\n",
      "1. GPT-3 (Generative Pre-trained Transformer 3): Desarrollado por OpenAI, es uno de los modelos más avanzados y potentes en NLP. Cuenta con 175 mil millones de parámetros y ha demostrado ser capaz de realizar tareas de generación de texto, traducción, resumen, entre otros.\n",
      "\n",
      "2. BERT (Bidirectional Encoder Representations from Transformers): Desarrollado por Google, se basa en la arquitectura de Transformer. Es conocido por su capacidad de comprensión contextual y ha sido utilizado en una amplia gama de tareas de NLP, como etiquetado de entidades, clasificación de texto y respuesta a preguntas.\n",
      "\n",
      "3. GPT-2 (Generative Pre-trained Transformer 2): También desarrollado por OpenAI, es un modelo anterior a GPT-3. Aunque cuenta con menos parámetros, sigue siendo muy efectivo en tareas de generación de texto, traducción y resumen.\n",
      "\n",
      "4. RoBERTa (Robustly Optimized BERT): Es una versión mejorada de BERT desarrollada por Facebook AI. RoBERTa ha obtenido resultados sobresalientes en varias tareas de NLP, especialmente en tareas de comprensión de texto y clasificación de sentiment.\n",
      "\n",
      "5. XLNet: Es otro modelo basado en la arquitectura de Transformer, pero con algunas mejoras. XLNet ha demostrado ser muy efectivo en tareas de modelado de lenguaje, generación de texto y traducción.\n",
      "\n",
      "Es importante tener en cuenta que la clasificación de los mejores modelos puede variar dependiendo del contexto y los objetivos específicos de cada tarea en NLP.\n"
     ]
    }
   ],
   "source": [
    "print(respuesta_gpt.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate   # la clase más basica de template\n",
    "\n",
    "mi_template_basico = '''\n",
    "Eres un orientador escolar el cual vas a orientar a alumnos \n",
    "para que sean expertos en la temática que les guste, les vas \n",
    "a hacer una roadmap de lo que deben aprender.\n",
    "Pregunta: '¿Que debo aprender para ser experto en {tematica}\n",
    "Respuesta: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eres un orientador escolar el cual vas a orientar a alumnas \n",
      "para que sean expertos en la temática que les guste, les vas \n",
      "a hacer una roadmap de lo que deben aprender.\n",
      "Pregunta: '¿Que debo aprender para ser experto en computer vision\n",
      "Respuesta: \n"
     ]
    }
   ],
   "source": [
    "# contruyo el template indicando cuales son las variables de entrada\n",
    "prompt_temp = PromptTemplate(input_variables= [\"tematica\"], template= mi_template_basico)\n",
    "\n",
    "# ahora reemplazamos la variable tematica por un tema en especifico\n",
    "prompt_value= prompt_temp.format(tematica= \"computer vision\")\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Para ser experto en computer vision, deberías aprender lo siguiente: \n",
      "\n",
      "1. Conceptos básicos de computación: comprensión de lenguajes de programación, algoritmos y estructuras de datos, conceptos de computación en la nube, etc. \n",
      "\n",
      "2. Conceptos básicos de visión artificial: algoritmos de procesamiento de imágenes y videos, reconocimiento facial y de objetos, análisis y clasificación de patrones, modelos de aprendizaje automático, etc. \n",
      "\n",
      "3. Herramientas y tecnologías específicas: OpenCV, TensorFlow, Caffe, Keras, Scikit-learn, etc. \n",
      "\n",
      "4. Programación orientada a objetos y orientada a servicios. \n",
      "\n",
      "5. Desarrollo de aplicaciones de visión artificial: creación de sistemas de visión artificial capaces de realizar\n"
     ]
    }
   ],
   "source": [
    "respusta_openai_2 = llm_openai(prompt_value)\n",
    "print(respusta_openai_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# podmeos ver cuantos tokens le estamos mandando al modelo\n",
    "# pip install  tiktoken\n",
    "llm_openai.get_num_tokens(prompt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatPromtTemplates\n",
    "\n",
    "Estos modelos ayudan a darle la info a los modelos de chat de una manera determinada.\n",
    "\n",
    "Los elementos principales son: \n",
    "\n",
    "- Human: El texto del usuario\n",
    "- AI: El texto que responde el modelo\n",
    "- System: El texto que se le envía al modelo para darle contexto de su funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, AIMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt del sistema\n",
    "prompt_temp_sistema = PromptTemplate(\n",
    "    template= '''\n",
    "            Eres un orientador escolar experto en {maestria} el cual vas a orientar a alumnos \n",
    "            para que sean profesionales en la temática que les guste, les vas \n",
    "            a hacer una roadmap de lo que deben aprender, partiendo de una base.''',\n",
    "    input_variables=['maestria']\n",
    ")\n",
    "\n",
    "template_sistema = SystemMessagePromptTemplate(prompt= prompt_temp_sistema)\n",
    "\n",
    "\n",
    "# prompt del humano\n",
    "prompt_temp_human = PromptTemplate(\n",
    "    template= 'Quiero ser experto en {tematica} y actualmente soy {base}', \n",
    "    input_variables= [\"tematica\", \"base\"])\n",
    "\n",
    "template_human = HumanMessagePromptTemplate(prompt= prompt_temp_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='\\n            Eres un orientador escolar experto en Inteligencia artificial el cual vas a orientar a alumnos \\n            para que sean profesionales en la temática que les guste, les vas \\n            a hacer una roadmap de lo que deben aprender, partiendo de una base.'), HumanMessage(content='Quiero ser experto en MLOps y actualmente soy Junior ML engineer')]\n"
     ]
    }
   ],
   "source": [
    "# ahora meteemos todo en otro template del prompt\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([template_sistema, template_human])\n",
    "\n",
    "\n",
    "chat_prompt_value = chat_prompt.format_prompt(maestria= 'Inteligencia artificial', tematica= 'MLOps', base= 'Junior ML engineer').to_messages()\n",
    "print(chat_prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='¡Genial! Ser experto en MLOps es una excelente elección, ya que combina el conocimiento de Machine Learning con habilidades de ingeniería y gestión de operaciones. Aquí te presento una roadmap para que puedas desarrollarte en esta área:\\n\\n1. Fundamentos de Machine Learning:\\n   - Asegúrate de tener una sólida comprensión de los conceptos básicos de Machine Learning, como algoritmos de clasificación, regresión y agrupamiento, así como de evaluación de modelos.\\n\\n2. Lenguaje de programación:\\n   - Profundiza tus conocimientos en Python, ya que es el lenguaje de programación más comúnmente utilizado en Machine Learning. Aprende a utilizar bibliotecas populares como NumPy, Pandas y Scikit-learn.\\n\\n3. Infraestructura y herramientas de ML:\\n   - Familiarízate con las principales herramientas y plataformas de Machine Learning, como TensorFlow, PyTorch y scikit-learn. Aprende a implementar y entrenar modelos de manera eficiente.\\n\\n4. DevOps y CI/CD:\\n   - Para convertirte en un experto en MLOps, es importante comprender los principios de DevOps (Desarrollo y Operaciones) y cómo aplicarlos al desarrollo de modelos de Machine Learning. Aprende a utilizar herramientas como Docker y Kubernetes para el despliegue y la gestión de modelos.\\n\\n5. Gestión de versiones y control de código:\\n   - Adquiere habilidades en el uso de sistemas de control de versiones, como Git, para mantener un seguimiento de los cambios en tu código y colaborar eficientemente con otros miembros del equipo.\\n\\n6. Automatización de pipelines de ML:\\n   - Aprende a construir pipelines de Machine Learning automatizados, desde la recolección y preprocesamiento de datos hasta el entrenamiento y despliegue de modelos. Puedes utilizar herramientas como Airflow o Kubeflow para esto.\\n\\n7. Monitoreo y mantenimiento:\\n   - Adquiere conocimientos sobre cómo monitorear y mantener modelos en producción. Aprende a detectar y solucionar problemas de rendimiento, a realizar actualizaciones de manera segura y a garantizar la calidad y robustez de los modelos en producción.\\n\\n8. Conocimientos en la nube:\\n   - Familiarízate con las principales plataformas en la nube, como AWS, Google Cloud o Azure, ya que suelen ser utilizadas para implementar soluciones de MLOps a gran escala.\\n\\n9. Mejores prácticas y tendencias:\\n   - Mantente actualizado sobre las últimas tendencias y mejores prácticas en el campo de MLOps. Participa en comunidades en línea, asiste a conferencias y lee blogs y libros relevantes.\\n\\nRecuerda que esta roadmap es solo una guía general y puedes adaptarla según tus necesidades y objetivos específicos. ¡Buena suerte en tu camino para convertirte en un experto en MLOps!'\n"
     ]
    }
   ],
   "source": [
    "chat_resp = chatGPT(chat_prompt_value)\n",
    "print(chat_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Genial! Ser experto en MLOps es una excelente elección, ya que combina el conocimiento de Machine Learning con habilidades de ingeniería y gestión de operaciones. Aquí te presento una roadmap para que puedas desarrollarte en esta área:\n",
      "\n",
      "1. Fundamentos de Machine Learning:\n",
      "   - Asegúrate de tener una sólida comprensión de los conceptos básicos de Machine Learning, como algoritmos de clasificación, regresión y agrupamiento, así como de evaluación de modelos.\n",
      "\n",
      "2. Lenguaje de programación:\n",
      "   - Profundiza tus conocimientos en Python, ya que es el lenguaje de programación más comúnmente utilizado en Machine Learning. Aprende a utilizar bibliotecas populares como NumPy, Pandas y Scikit-learn.\n",
      "\n",
      "3. Infraestructura y herramientas de ML:\n",
      "   - Familiarízate con las principales herramientas y plataformas de Machine Learning, como TensorFlow, PyTorch y scikit-learn. Aprende a implementar y entrenar modelos de manera eficiente.\n",
      "\n",
      "4. DevOps y CI/CD:\n",
      "   - Para convertirte en un experto en MLOps, es importante comprender los principios de DevOps (Desarrollo y Operaciones) y cómo aplicarlos al desarrollo de modelos de Machine Learning. Aprende a utilizar herramientas como Docker y Kubernetes para el despliegue y la gestión de modelos.\n",
      "\n",
      "5. Gestión de versiones y control de código:\n",
      "   - Adquiere habilidades en el uso de sistemas de control de versiones, como Git, para mantener un seguimiento de los cambios en tu código y colaborar eficientemente con otros miembros del equipo.\n",
      "\n",
      "6. Automatización de pipelines de ML:\n",
      "   - Aprende a construir pipelines de Machine Learning automatizados, desde la recolección y preprocesamiento de datos hasta el entrenamiento y despliegue de modelos. Puedes utilizar herramientas como Airflow o Kubeflow para esto.\n",
      "\n",
      "7. Monitoreo y mantenimiento:\n",
      "   - Adquiere conocimientos sobre cómo monitorear y mantener modelos en producción. Aprende a detectar y solucionar problemas de rendimiento, a realizar actualizaciones de manera segura y a garantizar la calidad y robustez de los modelos en producción.\n",
      "\n",
      "8. Conocimientos en la nube:\n",
      "   - Familiarízate con las principales plataformas en la nube, como AWS, Google Cloud o Azure, ya que suelen ser utilizadas para implementar soluciones de MLOps a gran escala.\n",
      "\n",
      "9. Mejores prácticas y tendencias:\n",
      "   - Mantente actualizado sobre las últimas tendencias y mejores prácticas en el campo de MLOps. Participa en comunidades en línea, asiste a conferencias y lee blogs y libros relevantes.\n",
      "\n",
      "Recuerda que esta roadmap es solo una guía general y puedes adaptarla según tus necesidades y objetivos específicos. ¡Buena suerte en tu camino para convertirte en un experto en MLOps!\n"
     ]
    }
   ],
   "source": [
    "print(chat_resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example selector (few shot learning)\n",
    "\n",
    "Cuando estamos usando un modelo probablemente queremos darle un par de ejemplos para influir en el tipo de respuesta que nos brinda, con example selector odemos hacer esto de manera sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# primero heacemos una lista de ejemplos de los que queremos que el modelo aprenda\n",
    "ejemplos = [\n",
    "    {\"pregunta\": \"¿Cual es la principal diferencia entre el aprendizaje supervisado y el no supervisado\", \"respuesta\":\"En uno tenemos etiquetas y en el otro no, en uno  es un enfoque predictivo y en el otro descriptivo\"},\n",
    "    {\"pregunta\": \"¿Cual es la principal carácterística del deep learning\", \"respuesta\":\"Su arquitectura de capas ocultas\"},\n",
    "    {\"pregunta\": \"¿En qué se basa la lógica difusa\", \"respuesta\":\"En que las personas no pensamos en términos numéricos sino en etiquetas linguísticas\"},\n",
    "]\n",
    "\n",
    "# se arma el template para el modelo\n",
    "#con la plantilla le decimos como queremos que formatee el prompt\n",
    "prompt_temp_ejemplos = PromptTemplate(input_variables=[\"pregutna\", \"respuesta\"], \n",
    "                                      template= \"Pregunta: {pregunta}\\nRespuesta: {respuesta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ejemplos = FewShotPromptTemplate(example_prompt= prompt_temp_ejemplos, \n",
    "                                        examples= ejemplos, \n",
    "                                        prefix= \"Eres asistente virtual de temas de inteligencia artificial que responde de manera breve pero efectiva\", \n",
    "                                        suffix= \"Pregunta: {pregunta}\\nRespuesta:\",        # esperamos que el modelo responda la pregunta\n",
    "                                        input_variables= [\"pregunta\"])                     # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eres asistente virtual de temas de inteligencia artificial que responde de manera breve pero efectiva\n",
      "\n",
      "Pregunta: ¿Cual es la principal diferencia entre el aprendizaje supervisado y el no supervisado\n",
      "Respuesta: En uno tenemos etiquetas y en el otro no, en uno  es un enfoque predictivo y en el otro descriptivo\n",
      "\n",
      "Pregunta: ¿Cual es la principal carácterística del deep learning\n",
      "Respuesta: Su arquitectura de capas ocultas\n",
      "\n",
      "Pregunta: ¿En qué se basa la lógica difusa\n",
      "Respuesta: En que las personas no pensamos en términos numéricos sino en etiquetas linguísticas\n",
      "\n",
      "Pregunta: ¿que diferencia hay entre el Reinforcement learning y el aprendizaje supervisado no supervisado?\n",
      "Respuesta:\n"
     ]
    }
   ],
   "source": [
    "prompt_value = prompt_ejemplos.format(pregunta= \"¿que diferencia hay entre el Reinforcement learning y el aprendizaje supervisado no supervisado?\")\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_respuesta = llm_openai(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El aprendizaje reforzado involucra la obtención de recompensas y castigos para aprender una tarea, mientras que el aprendizaje supervisado y no supervisado no implica ningún tipo de recompensa o castigo.\n"
     ]
    }
   ],
   "source": [
    "print(mi_respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_respuesta_sin_few_shot = llm_openai(\"¿que diferencia hay entre el Reinforcement learning y el aprendizaje supervisado no supervisado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Reinforcement Learning es una forma de aprendizaje automático en la que un agente interactúa con su entorno para maximizar una recompensa a largo plazo. El agente aprende a través de la retroalimentación del entorno. En cambio, el aprendizaje supervisado y no supervisado son formas de aprendizaje automático en las que los datos se utilizan para generar un modelo predictivo. El aprendizaje supervisado utiliza un conjunto de datos etiquetados para entrenar el modelo, mientras que el aprendizaje no supervisado utiliza un conjunto de datos no etiquetados para descubrir patrones.\n"
     ]
    }
   ],
   "source": [
    "print(mi_respuesta_sin_few_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output parser\n",
    "\n",
    "Langchain también nos da la opertunidad de parsear o formatear las respuestas que no dá el modelo de alguna manera que nos sea útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_basico_parser = \"\"\"\n",
    "Cuales son las características principales de {tema}\\n{como_parsear}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_temp_parser = PromptTemplate(input_variables=[\"tema\"],                                  # variable de entrada\n",
    "                                    template= template_basico_parser,                          # el template que va a utilizar\n",
    "                                    partial_variables= {\"como_parsear\": format_instructions})  # el formato que queremos la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value_parser = prompt_temp_parser.format(tema= 'Deep learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta_parser = llm_openai(prompt_value_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aprendizaje profundo automático, redes neuronales profundas, aprendizaje por refuerzo, algoritmos de aprendizaje profundo, técnicas de regularización, capas ocultas, aprendizaje de características, aprendizaje no supervisado, redes convolucionales, aprendizaje por transferencia.\n"
     ]
    }
   ],
   "source": [
    "print(respuesta_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aprendizaje profundo automático',\n",
       " 'redes neuronales profundas',\n",
       " 'aprendizaje por refuerzo',\n",
       " 'algoritmos de aprendizaje profundo',\n",
       " 'técnicas de regularización',\n",
       " 'capas ocultas',\n",
       " 'aprendizaje de características',\n",
       " 'aprendizaje no supervisado',\n",
       " 'redes convolucionales',\n",
       " 'aprendizaje por transferencia.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(respuesta_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
