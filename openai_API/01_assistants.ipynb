{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASISTENTES DE OPENAI\n",
    "\n",
    "https://platform.openai.com/docs/assistants/overview\n",
    "\n",
    "https://github.com/openai/openai-python/blob/main/examples/assistant.py\n",
    "\n",
    "La API de Asistentes te permite construir asistentes de inteligencia artificial dentro de tus propias aplicaciones. Un Asistente tiene instrucciones y puede aprovechar modelos, herramientas y conocimiento para responder a las consultas de los usuarios. Actualmente, la API de Asistentes admite tres tipos de herramientas: Intérprete de Código, Recuperación y Llamado de Funciones. En el futuro, planeamos lanzar más herramientas construidas por OpenAI y permitir que proporcionen sus propias herramientas en nuestra plataforma.\n",
    "\n",
    "Puedes explorar las capacidades de la API de Asistentes utilizando el playground de Asistentes o construyendo una integración paso a paso descrita en esta guía. A un alto nivel, una integración típica de la API de Asistentes tiene el siguiente flujo:\n",
    "\n",
    "- Crear un Asistente en la API definiendo sus instrucciones personalizadas y eligiendo un modelo. Si es útil, habilita herramientas como Intérprete de Código, Recuperación y Llamado de Funciones.\n",
    "- Crear un Hilo cuando un usuario inicia una conversación.\n",
    "- Añadir Mensajes al Hilo a medida que el usuario hace preguntas.\n",
    "- Ejecutar el Asistente en el Hilo para desencadenar respuestas. Esto llama automáticamente a las herramientas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno desde .env\n",
    "load_dotenv()\n",
    "\n",
    "# Acceder a la API key\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Crear un Asistente\n",
    "\n",
    "Un Asistente representa una entidad que puede ser configurada para responder a los Mensajes de los usuarios utilizando varios parámetros como:\n",
    "\n",
    "- Instructions: cómo debe comportarse o responder el Asistente y el modelo.\n",
    "- Model: puedes especificar cualquier modelo de GPT-3.5 o GPT-4, incluyendo modelos afinados. La herramienta de Recuperación requiere los modelos gpt-3.5-turbo-1106 y gpt-4-1106-preview.\n",
    "- Tools: la API soporta Intérprete de Código y Recuperación que están construidos y alojados por OpenAI.\n",
    "- Functions: la API te permite definir firmas de funciones personalizadas, con un comportamiento similar a nuestra característica de llamado a funciones.\n",
    "\n",
    "En este ejemplo, estamos creando un Asistente que es un tutor personal de matemáticas, con la herramienta de Intérprete de Código habilitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = openai.OpenAI()\n",
    "\n",
    "assistant = openai.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    #api_key= api\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Crear un Hilo ---> Thread\n",
    "\n",
    "Un Hilo representa una conversación. Recomendamos crear un Hilo por usuario tan pronto como el usuario inicie la conversación. Pasa cualquier contexto específico del usuario y archivos en este hilo creando Mensajes.\n",
    "\n",
    "Los Hilos no tienen un límite de tamaño. Puedes añadir tantos Mensajes como desees a un Hilo. El Asistente se asegurará de que las solicitudes al modelo se ajusten dentro de la ventana de contexto máxima, utilizando técnicas de optimización relevantes como la truncación, las cuales hemos probado extensamente con ChatGPT. Cuando usas la API de Asistentes, delegas el control sobre cuántos tokens de entrada se pasan al modelo para cualquier ejecución dada, esto significa que tienes menos control sobre el costo de ejecutar tu Asistente en algunos casos, pero no tienes que lidiar con la complejidad de gestionar la ventana de contexto tú mismo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openai.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3 añadir un mensaje al hilo\n",
    "\n",
    "Un Mensaje contiene texto y, opcionalmente, cualquier archivo que permitas que el usuario suba. Los Mensajes necesitan ser añadidos a un Hilo específico. Añadir imágenes a través de objetos de mensaje como en Completados de Chat usando GPT-4 con Visión no es soportado hoy en día, pero planeamos añadir soporte para ellos en los próximos meses. Aún puedes subir imágenes y procesarlas a través de la recuperación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = openai.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread_messages = openai.beta.threads.messages.list(\"thread_abc123\")\n",
    "# print(thread_messages.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Ejecutar el Asistente\n",
    "\n",
    "Para que el Asistente responda al mensaje del usuario, necesitas crear una Ejecución. Esto hace que el Asistente lea el Hilo y decida si llamar a herramientas (si están habilitadas) o simplemente usar el modelo para responder mejor a la consulta. A medida que la ejecución avanza, el asistente añade Mensajes al hilo con el rol=\"assistant\". El Asistente también decidirá automáticamente qué Mensajes anteriores incluir en la ventana de contexto para el modelo. \n",
    "\n",
    "Esto tiene un impacto tanto en la tarificación como en el rendimiento del modelo. El enfoque actual ha sido optimizado basado en lo que aprendimos al construir ChatGPT y probablemente evolucionará con el tiempo.\n",
    "\n",
    "Opcionalmente, puedes pasar nuevas instrucciones al Asistente al crear la Ejecución, pero ten en cuenta que estas instrucciones anulan las instrucciones predeterminadas del Asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = openai.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Verificar el estado de la Ejecución\n",
    "Por defecto, una Ejecución entra en estado de en cola. Puedes recuperar periódicamente la Ejecución para verificar su estado y ver si ha pasado a completado.\n",
    "\n",
    "## Paso 6: Mostrar la Respuesta del Asistente\n",
    "Una vez que la Ejecución se completa, puedes listar los Mensajes añadidos al Hilo por el Asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking assistant status. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in progress...\n",
      "in progress...\n",
      "in progress...\n",
      "in progress...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\plane\\OneDrive\\Escritorio\\COMPUTING SCIENCE\\Apuntes_plantillas\\openai_API\\01_assistants.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/Apuntes_plantillas/openai_API/01_assistants.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/Apuntes_plantillas/openai_API/01_assistants.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39min progress...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/Apuntes_plantillas/openai_API/01_assistants.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"checking assistant status. \")\n",
    "while True:\n",
    "    run = openai.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    if run.status == \"completed\":\n",
    "        print(\"done!\")\n",
    "        messages = openai.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "        print(\"messages: \")\n",
    "        for message in messages:\n",
    "            assert message.content[0].type == \"text\"\n",
    "            print({\"role\": message.role, \"message\": message.content[0].text.value})\n",
    "\n",
    "        openai.beta.assistants.delete(assistant.id)\n",
    "\n",
    "        break\n",
    "    else:\n",
    "        print(\"in progress...\")\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = openai.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_hURyu6ICTFPF5OdnXklMfKww', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1701775679, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ePyNXLCjzj1Wkxp6PuFhuwr'), ThreadMessage(id='msg_44J4n9xzGflnsaAGttH8e7Ft', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1701775585, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_5ePyNXLCjzj1Wkxp6PuFhuwr')], object='list', first_id='msg_hURyu6ICTFPF5OdnXklMfKww', last_id='msg_44J4n9xzGflnsaAGttH8e7Ft', has_more=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
